---
permalink: /activities/gsoc/2023
title: "GSoC 2023"

youtubeId1: wmAeoyiUyh4
youtubeId2: 07RnI9bXysk
youtubeId3: Y5VvQAP6cMI
youtubeId4: AGJlCJ6UXPs
youtubeId5: gDP9nWCL0Vg
youtubeId6: kJMPz80w9BM
youtubeId7: YMMQVo_3oh8
youtubeId8: ufvPS5wJAx0
youtubeId9: y7rBPpV2NdI
youtubeId10: BpHSDrFqpVk
youtubeId11: yKXP3UIAxtg
youtubeId12: tzxxEyA-LWs
youtubeId13: s-S5mQp9i1Y
youtubeId14: 4yKM3EuEv_g
youtubeId15: NrzmH_yerBU
youtubeId16: 97JRYhKLhSY
youtubeId17: vn4ahq8mElg
youtubeId18: sXqZvsV5lzc
youtubeId19: RfW2hI_8j74
youtubeId20: WMRDqv3TYB0
youtubeId21: J6bDlE7TofE
youtubeId41: W3XirsadmNg
youtubeId50: 7s4vpMGU2Mg

sidebar:
  nav: "docs"

toc: true
toc_label: "TOC GSoC-2023 (in case of being selected)"
toc_icon: "cog"

projects:
  - image_path: /assets/images/activities/gsoc/2022_toshan-luktuke.jpg
    alt: "GSoC 2022 - Toshan Luktuke"
    title: "Toshah Luktuke"
    excerpt: "Improvement of VisualCircuit web service"
    url: "https://github.com/TheRoboticsClub/gsoc2022-Toshan_Luktuke"
    btn_class: "btn--info"
    btn_label: "Project #7"
  - image_path: /assets/images/activities/gsoc/2022_nikhil-paliwal.jpg
    alt: "GSoC 2022 - Nikhil Paliwal"
    title: "Nikhil Paliwal"
    excerpt: "Optimization of Deep Learning models for autonomous driving"
    url: "https://github.com/TheRoboticsClub/gsoc2022-Nikhil_Paliwal"
    btn_class: "btn--info"
    btn_label: "Project #8"
  - image_path: /assets/images/activities/gsoc/2022_prakarsh-kaushik.jpg
    alt: "GSoC 2022 - Prakarsh Kaushik"
    title: "Prakarsh Kaushik"
    excerpt: "Robotics Academy: consolidation of drone based exercises"
    url: "https://github.com/TheRoboticsClub/gsoc2022-Prakarsh_Kaushik"
    btn_class: "btn--info"
    btn_label: "Project #2"
  - image_path: /assets/images/activities/gsoc/2022_akshay-narisetti.jpg
    alt: "GSoC 2022 - Akshay Narisetti"
    title: "Akshay Narisetti"
    excerpt: "Robotics Academy: improvement of autonomous driving exercises"
    url: "https://github.com/TheRoboticsClub/gsoc2022-Akshay_Narisetti"
    btn_class: "btn--info"
    btn_label: "Project #3"
  - image_path: /assets/images/activities/gsoc/2022_pratik-mishra.jpg
    alt: "GSoC 2022 - Pratik Mishra"
    title: "Pratik Mishra"
    excerpt: "Robotics Academy: migration of several exercises from ROS1 to ROS2 and refinement"
    url: "https://github.com/TheRoboticsClub/gsoc2022-Pratik_Mishra"
    btn_class: "btn--info"
    btn_label: "Project #10"
  - image_path: /assets/images/activities/gsoc/2022_bhavesh-misra.jpg
    alt: "GSoC 2022 - Bhavesh Misra"
    title: "Bhavesh Misra"
    excerpt: "Robotics Academy: improve Deep Learning based Human Detection exercise"
    url: "https://github.com/TheRoboticsClub/gsoc2022-Bhavesh_Misra"
    btn_class: "btn--info"
    btn_label: "Project #4"
  - image_path: /assets/images/activities/gsoc/2022_apoorv-garg.jpg
    alt: "GSoC 2022 - Apoorv Garg"
    title: "Apoorv Garg"
    excerpt: "Robotics Academy: improvement of the web templates using powerful frontend technologies"
    url: "https://github.com/TheRoboticsClub/gsoc2022-Apoorv_Garg"
    btn_class: "btn--info"
    btn_label: "Project #6"
    
---

Robotics applications are typically distributed, made up of a collection of concurrent asynchronous components which communicate using some middleware (ROS messages, DDS...). Building robotics applications is a complex task. Integrating existing nodes or libraries that provide already solved functionality, and using several tools may increase the software robustness and shorten the development time. JdeRobot provides several tools, libraries and reusable nodes. They have been written in C++, Python or JavaScript. They are ROS-friendly and full compatible with ROS-Noetic, ROS2-Foxy (and Gazebo11).


Our community mainly works on four development areas:
- Education in Robotics. [RoboticsAcademy](https://jderobot.github.io/RoboticsAcademy/) is our main project. It is a ROS-based framework to learn robotics and computer vision with drones, autonomous cars.... It is a collection of Python programmed exercises for engineering students. 

- Robot Programming Tools. For instance, [VisualCircuit](https://jderobot.github.io/VisualCircuit/) for robot programming with connected blocks, as in eleectronic circuits, in a visual way.

- MachineLearning in Robotics. For instance, [DeepLearningStudio](https://github.com/JdeRobot/DeepLearningStudio) to explore the use neural networks for robot control. It includes the [BehaviorMetrics tool](https://jderobot.github.io/BehaviorMetrics/) for assessment of neural networks for autonomous driving. [RL-Studio](https://github.com/JdeRobot/RL-Studio), a library for the training of Reinforcement Learning algorithms for robot control. [DetectionMetrics tool](https://github.com/JdeRobot/DetectionMetrics) for evaluation of visual detection neural networks and algorithms.

- Reconfigurable Computing in Robotics. [FPGA-Robotics](https://github.com/JdeRobot/FPGA-robotics) for programming robots with reconfigurable computing (FPGAs) using open tools as IceStudio and Symbiflow. Verilog-based reusable blocks for robotics applications.




# Selected contributors

In the year 2022, the contributors selected for the Google Summer of Code have been the following:

{% include feature_row_advanced %}


# Ideas list

This open source organization welcomes contributors in these topics:


## Project #1: RoboticsAcademy: Cross-Platform Desktop Application using ElectronJS

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS or openCV. 

Currently, the platform offers its resources through a website, making it difficult for users to access and manage the content.The objective of this project is to develop a cross-platform desktop application for the Robotics Academy using ElectronJS. The application will provide a convenient and user-friendly interface for users to access and manage the content, making it more accessible and efficient for users to learn and explore the world of robotics.

The scope of this project is to develop a cross-platform desktop application for the Robotics Academy using ElectronJS. The application will be designed to provide a user-friendly interface for users to access and manage the resources and content available on the Robotics Academy platform. The project will involve the integration of the existing resources and content into the application, as well as the implementation of features such as resource management and a user-friendly interface. The project will also include thorough testing and bug fixing to ensure the stability and usability of the application. Finally, the project will involve documenting the project and providing clear instructions for future maintenance and development.

{% include youtubePlayer.html id=page.youtubeId7 %}

- **Skills required/preferred:** Proficiency in JavaScript and ElectronJS framework
- **Difficulty rating:** medium
- **Expected results:** desktop application for Robotics Academy
- **Expected size:** 175h
- **Mentors:** Apoorv Garg (apoorvgarg.ms AT gmail.com) 



## Project #2: Robotics Academy: consolidation of drone based exercises

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS or openCV.

Currently there are [9 drone exercises](https://jderobot.github.io/RoboticsAcademy/exercises/drones_section) available, all as web-templates (RoboticsAcademy v3.2) and two more are about to come. Project's goal is to consolidate the existing exercises, improving front-end appealing and extending drones back-end (PX4 and JdeRobot's dronewrapper) with new functionalities, such as adding support to new control methods or new sensors (IR, depth cameras, etc). The project may also explore the develompent of new drone exercises or extending support to real drones.

You will work with Docker, Gazebo-11 and ROS-noetic. Also, using ROS2 for these exercises will be explored.

<figure class="half">
    <a href=""><iframe src="https://www.youtube.com/embed/fISm9Q2_ogg"></iframe></a>
    <a href=""><iframe src="https://www.youtube.com/embed/0dV8OkTG0pM"></iframe></a>
 </figure>

- **Skills required/preferred:** Python, OpenCV, ROS, HTML, CSS and Django.
- **Difficulty rating:** medium
- **Expected results:** ROS-based drones exercises.
- **Expected size:** 175h
- **Mentors:** Pedro Arias (pedroariasperez96 AT gmail.com) and Arkajyoti Basak (arkajbasak121 AT gmail.com)



## Project #3: Robotics Academy: improvement of autonomous driving exercises

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS or openCV.

Currently there are four exercises regarding autonomous driving exercises in RoboticsAcademy: [local navigation](https://jderobot.github.io/RoboticsAcademy/exercises/AutonomousCars/obstacle_avoidance), [global navigation](https://jderobot.github.io/RoboticsAcademy/exercises/AutonomousCars/global_navigation/), [autoparking](https://jderobot.github.io/RoboticsAcademy/exercises/AutonomousCars/autoparking/) and [car junction](https://jderobot.github.io/RoboticsAcademy/exercises/AutonomousCars/car_junction/). The car models have to be improved to be more realistic, use Ackermann control and LIDAR sensor onboard. ROS2 use for these exercises will be explored. Tentative solutions will be also developed.

{% include youtubePlayer.html id=page.youtubeId10 %}

{% include youtubePlayer.html id=page.youtubeId16 %}

- **Skills required/preferred:** Python programming skills, Gazebo.
- **Difficulty rating:** medium
- **Expected results:** more realistic ROS-based autonomous driving exercises 
- **Expected size:** 175h
- **Mentors:** Luis Roberto Morales (lr.morales.iglesias AT gmail.com), José María Cañas (josemaria.plaza AT gmail.com)


## Project #4: Robotics-Academy: improve Deep Learning based Human Detection exercise

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS or openCV.

The idea for this project is to improve the ["Human detection" Deep Learning exercise](https://jderobot.github.io/RoboticsAcademy/exercises/ComputerVision/human_detection) at Robotics-Academy, developed along GSoC-2021. Instead of asking the user to code the solution in a web-based editor, he or she will have to upload a deep learning model that matches video inputs and outputs the image coordinates of the detected humans. In this project, the support for neural network models in the open [ONNX format](https://onnx.ai/), which is becoming a standard, is one goal. The exercise fluent execution is also a goal, hopefully taking advantage of GPU at the user's machine from the RoboticsAcademy docker container. An automatic evaluator to test the performance of the network provided by the user will be also explored. All the above functionalities have, to some extent, already been implemented in the exercise. The goal is to improve/refine them either on the existing implementation or from scratch.
In short, the scope of improvements in the exercise include:

- Custom train or find an enhanced DL model trained to detect only humans specifically. Changes to the pre-processing and post-processing part would have to be made as per the input and output structure of the new model.
- Enhancing the model benchmarking part in terms of its interpretability, use case, accuracy, and visual appeal to the user. 
- Enabling GPU support while executing the exercise from the docker container.
- Fluent exercise execution.
- Other scopes of improvements are also welcome. This may include adding/modifying features and making the exercise more user-friendly and easy to use.

{% include youtubePlayer.html id=page.youtubeId17 %}

- **Skills required/preferred:** Python, OpenCV, PyTorch/Tensorflow
- **Difficulty rating:** medium
- **Expected results:** a web-based exercise for solving a visual detection task using deep learning
- **Expected size:** 175h
- **Mentors:** David Pascual (d.pascualhe AT gmail.com) and Shashwat Dalakoti (shash.dal623 AT gmail.com)



## Project #5: Robotics-Academy: new exercise using Deep Learning for Visual Control

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS or openCV.

The idea for this project is to develop a new deep learning exercise for visual robotic control within the Robotics-Academy context. We will build a web-based interface that allows the user to input a trained model that matches as input the camera installed on a drone or a car, and as outputs the linear speed and angular velocity of the vehicle. The controlled robot and its environment will be simulated using Gazebo. In this project, we will:
- Update the web interface for accepting models trained with PyTorch/Tensorflow as input.
- Build new widgets for monitoring results for the particular exercise.
- Get a simulated environment ready.
- Code the core application that will feed the trained model with input data and send back the results.
- Train a naive model that allow us to show how the exercise can be solved.

This new exercise may reuse the infrastructure developed for the ["Human detection" Deep Learning exercise](https://jderobot.github.io/RoboticsAcademy/exercises/ComputerVision/human_detection). The following videos show one of our current web-based exercises and a visual control task solved using deep learning:

{% include youtubePlayer.html id=page.youtubeId14 %}

{% include youtubePlayer.html id=page.youtubeId50 %}

- **Skills required/preferred:** Python, OpenCV, PyTorch/Tensorflow, Gazebo
- **Difficulty rating:** medium
- **Expected results:** a web-based exercise for robotic visual control using deep learning
- **Expected size:** 175h
- **Mentors:** David Pascual ( d.pascualhe AT gmail.com ) and Pankhuri Vanjani (pankhurivanjani AT gmail.com)



## Project #6: Robotics-Academy: improvement of the web templates using powerful frontend technologies

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS or openCV.

For each exercise there is a webpage (exercise.html) and a Python template (exercise.py), both connected through websockets. The webpages are the Graphical User Interface (GUI) of each RoboticsAcademy exercise and they use several web templates. The browser connects with the Docker image application in order to run the simulation and to allow the users to send their code and see the results of the simulation. Nowadays, the web-templates have been developed using plain HTML, Javascript and CSS and we aim to improve them by using advanced frontend technologies such as React, Vue, Angular or Flutter. 

[![Color filter](https://img.youtube.com/vi/Fv9s99IEIvc/0.jpg)](https://www.youtube.com/watch?v=Fv9s99IEIvc)

{% include youtubePlayer.html id=page.youtubeId18 %} 

- **Skills required/preferred:** Python, JavaScript, HTML, CSS
- **Difficulty rating:** medium
- **Expected results:** Upgrade the current web templates of all exercises to use a more advanced frontend technology.
- **Expected size:** 350h
- **Mentors:** David Roldán (david.roldan AT urjc.es) and Jose María Cañas (josemaria.plaza AT urjc.es)



## Project #7: improvement of VisualCircuit web service

**Brief Explanation**: VisualCircuit allows users to program robotic intelligence using a visual language which consists of blocks and wires, as electronic circuits. In the last year, including GSoC-2021, the Graphical User Interface of this tool was migrated to REACT and a webserver was developed to provide its functionality as a [web service](https://visualcircuit.org). Anyone can try it out without going through the process of local installation. Only the ROS and Gazebo drivers are required locally to run the circuit developed at VisualCircuit webpage. Web server → Downloaded circuit file → Execute that file. You can read further about the tool on the [website](https://jderobot.github.io/VisualCircuit). In this way, VisualCircuit will be cross-platform, attract new users and be very convenient to use. 

We want to refine this tool developing several robot applications with it involving ROS2 robots and Gazebo simulator. Not only pure reactive robot applications but also more complex ones involving Finite State Machines, several different robot types (drones, indoor, outdoor...), and vision-based applications. In addition the Python implementation of blocks and wires from the visual design will be also refactored, hopefully achieving an cross-platform implementation which works both in both Linux and Windows machines.

 <img src="/assets/images/activities/gsoc/VisualCircuit.png" width="80%" height="80%">

{% include youtubePlayer.html id=page.youtubeId20 %}

<!--
<figure class="half">
  <img src="/assets/images/activities/gsoc/fpga-circuit.png" width="50%" height="60%">
  <img src="/assets/images/activities/gsoc/icestudio.png" width="50%" height="60%">
  <figcaption>VisualCircuit</figcaption>
</figure>
-->

- **Skills required/preferred:** Python, Django and some basic JavaScript knowledge
- **Difficulty rating:** medium
- **Expected results:** better Python synthesis and a set of robot applications developed with VisualCircuit
- **Expected size:** 175h
- **Mentors:** Muhammad Taha (mtsg09 AT gmail.com) and Suhas Gopal (suhas.g96.sg AT gmail.com)



## Project #8: optimization of Deep Learning models for autonomous driving

**Brief explanation**: [BehaviorMetrics](https://jderobot.github.io/BehaviorMetrics) is a tool used to compare different autonomous driving architectures. It uses [Gazebo](http://gazebosim.org/), a well-known really powerful robotics simulator and [ROS Noetic](http://wiki.ros.org/noetic). We are currently able to drive a car autonomously on different circuits using deep learning models to do the robot control processing. Check out the videos below to get an insight. 

For this project, we would like to improve the current model stack based on deep learning, applying some optimization techniques to make them run faster without losing precision. Since the hardware devices used to do the inference in real world scenarios usually have a small amount of compute capabilities, we would like to apply speed up techniques on our models or explore new model architectures with low inference time. Some references:

* [TensorRT](https://developer.nvidia.com/tensorrt)
* [Quantization](https://www.tensorflow.org/api_docs/python/tf/quantization/quantize)

 <img src="/assets/images/activities/gsoc/behavior-metrics-screenshot.png" width="80%" height="80%">
{% include youtubePlayer.html id=page.youtubeId21 %}

<!--
<figure class="half">
    <img src="/assets/images/activities/gsoc/behavior-metrics-screenshot.png">
    <a href=""><iframe src="https://www.youtube.com/embed/J6bDlE7TofE"></iframe></a>
 </figure>
-->

- **Skills required/preferred:** Python and deep learning knowledge (Tensorflow/PyTorch).
- **Difficulty rating:** medium
- **Expected results:** new autonomous driving deep learning models optimized for lower inference time.
- **Expected size:** 175h
- **Mentors:** Sergio Paniego Blanco (sergiopaniegoblanco AT gmail.com) and Utkarsh Mishra ( utkarsh75477 AT gmail.com )


## Project #9: DeepLearning models for autonomous drone piloting and support in BehaviorMetrics

**Brief Explanation**: [BehaviorMetrics](https://jderobot.github.io/BehaviorMetrics) is a tool used to compare different autonomous driving architectures. It uses [Gazebo](http://gazebosim.org/), a well-known really powerful robotics simulator and [ROS Noetic](http://wiki.ros.org/noetic). During a past GSoC 2021 [project](https://theroboticsclub.github.io/gsoc2021-Utkarsh_Mishra/gsoc/Summary-and-Recap/), we explored the addition of drone support for Behavior Metrics. We were able to add this support for IRIS drone, so we would like to exploring adding autonomous drone piloting techniques based on deep learning for this configuration. 

We would like to generate new drone scenarios specially suited for the robot control problem, train deep learning models based on state of the art architectures and refine this support in the BehaviorMetrics stack. The drone 3D control is a step forward from the 2D car control, as there is an additional degree of freedom and the onboard camera orientation typically significantly oscillates while the vehicle is moving in 3D.

<figure class="half">
    <a href=""><iframe src="https://www.youtube.com/embed/GZs6OIQ_az0"></iframe></a>
    <a href=""><iframe src="https://www.youtube.com/embed/pbYfdXvtRLo"></iframe></a>
 </figure>

- **Skills required/preferred:** Python and deep learning knowledge (specially PyTorch).
- **Difficulty rating:** hard
- **Expected results:** broader support for the autonomous driving drone using Gazebo and PyTorch.
- **Expected size:** 350 hours
- **Mentors:** Sergio Paniego Blanco (sergiopaniegoblanco AT gmail.com) and Utkarsh Mishra ( utkarsh75477 AT gmail.com )



## Project #10: Robotics Academy: migration of several exercises from ROS1 to ROS2 and refinement

**Brief Explanation**: Currently most RoboticsAcademy exercises are based on ROS1 Noetic and Gazebo 11. There are also several prototypes of ROS2 Foxy based exercises which require refinement. The main goal of this project is to migrate several RADI-3 exercises to RADI-4, updating the models of the robots involved in those exercises to their homologous model in ROS2. This will require understanding the complete infrastructure and modifying exercises to use ROS2 communications. In addition, the support for several ROS tools (such as rqt_graph and Rviz) from the corresponding exercise webpages should be implemented (using VNC mainly). New exercises integrating the ROS2 Navigation stack are also welcome, which involve the use of functionalities such as collision avoidance, global path planning, and Multi-robot coordination.

ROS2 has put forward several improvements over ROS with changes in middleware and software architecture in many aspects. In this project, we would focus on developing new exercises with ROS2. For more information on ROS2 based exercises, have a look at [GSoC 2021 project](https://theroboticsclub.github.io/gsoc2021-Siddharth_Saha/milestones/2021/08/21/final-report) and corresponding academy exercises [1](https://jderobot.github.io/RoboticsAcademy/exercises/MobileRobots/single_robot_amazon_warehouse/) and [2](https://jderobot.github.io/RoboticsAcademy/exercises/MobileRobots/multi_robot_amazon_warehouse/). In addition to porting exercises, contributors are also welcome to suggest improvements to the current RADI framework.

{% include youtubePlayer.html id=page.youtubeId19 %}
{% include youtubePlayer.html id=page.youtubeId1 %}

- **Skills required/preferred:** C++, Python programming skills, experience with ROS. Good to know: ROS2
- **Difficulty rating:** hard
- **Expected results:** Migrating the current web template exercises from (ROS1 based) RADI-3 to (ROS2 based) RADI-4
- **Expected size:** 350 hours
- **Mentors:** Siddharth Saha (sahasiddharth611 AT gmail.com) and Shreyas Gokhale (shreyas6gokhale AT gmail.com).

# Application instructions for GSoC-2022

We welcome students to contact relevant mentors before submitting their application into GSoC official website. If in doubt for which project(s) to contact, send a message to jderobot AT gmail.com We recommend browsing previous GSoC student pages to look for ready-to-use projects, and to get an idea of the expected amount of work for a valid GSoC proposal.

## Requirements

* Git experience
* C++ and Python programming experience (depending on the project)

## Programming tests

|    **Project**   |     [#1](https://jderobot.github.io/activities/gsoc/2022#project-1-robotics-academy-optimization-of-exercise-templates)     |      [#2](https://jderobot.github.io/activities/gsoc/2022#project-2-robotics-academy-consolidation-of-drone-based-exercises)      |     [#3](https://jderobot.github.io/activities/gsoc/2022#project-3-robotics-academy-improvement-of-autonomous-driving-exercises)     |     [#4](https://jderobot.github.io/activities/gsoc/2022#project-4-robotics-academy-improve-deep-learning-based-human-detection-exercise)     |     [#5](https://jderobot.github.io/activities/gsoc/2022#project-5-robotics-academy-new-exercise-using-deep-learning-for-visual-control)     |     [#6](https://jderobot.github.io/activities/gsoc/2022#project-6-robotics-academy-improvement-of-the-web-templates-using-powerful-frontend-technologies)     |     [#7](https://jderobot.github.io/activities/gsoc/2022#project-7-improvement-of-visualcircuit-web-service)     |     [#8](https://jderobot.github.io/activities/gsoc/2022#project-8-optimization-of-deep-learning-models-for-autonomous-driving)     |     [#9](https://jderobot.github.io/activities/gsoc/2022#project-9-deeplearning-models-for-autonomous-drone-piloting-and-support-in-behaviormetrics)     |     [#10](https://jderobot.github.io/activities/gsoc/2022#project-10-robotics-academy-migration-of-several-exercises-from-ros1-to-ros2-and-refinement)    |
| **Academy (A)** |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |
|    **C++ (B)**   |     O     |     O     |     O     |     O     |     O     |     O     |     O     |     O     |     O     |     X     |
|  **Python (C)**  |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |
|  **ROS2 (D)**  |     O     |     O     |     O     |     O     |     O     |     -     |     -     |     -     |     -     |     X     |

<br/>

|               Where:                     ||
| * |             Not applicable            |
| X |                Mandatory              |
| O |                Optative               |


Before accepting any proposal all candidates have to do these programming challenges:

- (A) [RoboticsAcademy challenge](https://drive.google.com/file/d/1UaZt43_Sl-vI-mD_D6bRNWXLQpywdrIF/view?usp=sharing)
- (B) [C++ challenge](https://drive.google.com/file/d/1GO0GJIi7rNqZXhPEaV8Qf0Ds4qFHczJ2/view?usp=sharing)
- (C) [Python challenge](https://drive.google.com/file/d/1Mzr-jGvwCpuZoFKmvjXzJxTfjbf2K16w/view?usp=sharing)
- (D) [ROS2 challenge](https://drive.google.com/file/d/1q3-43jxPPqQRjRB_tX7Y_N07YKOfToC3/view?usp=sharing)

## Send us your information

AFTER doing the programming tests, fill this [web form](https://docs.google.com/forms/d/e/1FAIpQLSfQAt6NbTP_Thag4fa638zmXqR1gnPGQOYDOupIQ6ram9d1BA/viewform) with your information and challenge results. Then you are invited to ask the project mentors about the project details. Maybe we will require more information from you like this:


1. Contact details
   - Name and surname:
   - Country:
   - Email:
   - Public repository/ies:
   - Personal blog (optional):
   - Twitter/Identica/LinkedIn/others:
2. Timeline
   - Now split your project idea in smaller tasks. Quantify the time you think each task needs. Finally, draw a tentative project plan (timeline) including the dates covering all period of GSoC. Don’t forget to include also the days in which you don’t plan to code, because of exams, holidays etc.
   - Do you understand this is a serious commitment, equivalent to a full-time paid summer internship or summer job?
   - Do you have any known time conflicts during the official coding period?
3. Studies
   - What is your School and degree?
   - Would your application contribute to your ongoing studies/degree? If so, how?
4. Programming background
   - Computing experience: operating systems you use on a daily basis, known programming languages, hardware, etc.
   - Robot or Computer Vision programming experience:
   - Other software programming:
5. GSoC participation
   - Have you participated to GSoC before?
   - How many times, which year, which project?
   - Have you applied but were not selected? When?
   - Have you submitted/will you submit another proposal for GSoC 2022 to a different org?



# Previous GSoC students

- [Suhas Gopal](https://theroboticsclub.github.io/gsoc2021-Suhas_Gopal/) (GSoC-2021) Shifting VisualCircuit to a web server
- [Utkarsh Mishra](https://theroboticsclub.github.io/gsoc2021-Utkarsh_Mishra/) (GSoC-2021) Autonomous Driving drone with Gazebo using Deep Learning techniques
- [Siddharth Saha](https://theroboticsclub.github.io/gsoc2021-Siddharth_Saha/) (GSoC-2021) Robotics Academy: multirobot version of the Amazon warehouse exercise in ROS2
- [Shashwat Dalakoti](https://theroboticsclub.github.io/gsoc2021-Shashwat_Dalakoti/) (GSoC-2021) Robotics-Academy: exercise using Deep Learning for Visual Detection
- [Arkajyoti Basak](https://theroboticsclub.github.io/gsoc2021-Arkajyoti_Basak/) (GSoC-2021) Robotics Academy: new drone based exercises
- [Chandan Kumar](https://theroboticsclub.github.io/gsoc2021-Chandan_Kumar/) (GSoC-2021) Robotics Academy: Migrating industrial robot manipulation
 exercises to web server
- [Muhammad Taha](https://theroboticsclub.github.io/colab-gsoc2020-Muhammad_Taha/) (GSoC-2020) VisualCircuit tool, digital electronics language for robot behaviors.
- [Sakshay Mahna](https://theroboticsclub.github.io/colab-gsoc2020-Sakshay_Mahna/) (GSoC-2020) Robotics-Academy exercises on Evolutionary Robotics.
- [Shreyas Gokhale](https://theroboticsclub.github.io/colab-gsoc2020-Shreyas_Gokhale/) (GSoC-2020) Multi-Robot exercises for Robotics Academy In ROS2.
- [Yijia Wu](https://theroboticsclub.github.io/colab-gsoc2020-Yijia_Wu/) (GSoC-2020) Vision-based Industrial Robot Manipulation with MoveIt.
- [Diego Charrez](https://theroboticsclub.github.io/colab-gsoc2020-Diego_Charrez/logbook/) (GSoC-2020) Reinforcement Learning for Autonomous Driving with Gazebo and OpenAI gym.
- [Nikhil Khedekar](https://theroboticsclub.github.io/colab-gsoc2019-Nikhil_Khedekar/) (GSoC-2019) Migration to ROS of drones exercises on JdeRobot Academy
- [Shyngyskhan Abilkassov](https://theroboticsclub.github.io/colab-gsoc2019-Shyngyskhan_Abilkassov) (GSoC-2019) Amazon warehouse exercise on JdeRobot Academy
- [Jeevan Kumar](https://theroboticsclub.github.io/colab-gsoc2019-Jeevan_Kumar/) (GSoC-2019) Improving DetectionSuite DeepLearning tool
- [Baidyanath Kundu](https://theroboticsclub.github.io/colab-gsoc2019-Baidyanath_Kundu/) (GSoC-2019) A parameterized automata Library for VisualStates tool
- [Srinivasan Vijayraghavan](https://theroboticsclub.github.io/colab-gsoc2019-Srinivasan_Vijayraghavan/) (GSoC-2019) Running Python code on the web browser
- [Pankhuri Vanjani](https://theroboticsclub.github.io/colab-gsoc2019-Pankhuri_Vanjani/) (GSoC-2019) Migration of JdeRobot tools to ROS 2
- [Pushkal Katara](https://wiki.jderobot.org/Club-PushkalKatara) (GSoC-2018) VisualStates tool
- [Arsalan Akhter](https://wiki.jderobot.org/Club-aakhter) (GSoC-2018) Robotics-Academy
- [Hanqing Xie](https://wiki.jderobot.org/Club-hanqingxie) (GSoC-2018) Robotics-Academy
- [Sergio Paniego](https://wiki.jderobot.org/Club-spaniego) (GSoC-2018) PyOnArduino tool
- [Jianxiong Cai](https://wiki.jderobot.org/Club-jianxiong) (GSoC-2018) Creating realistic 3D map from online SLAM result
- [Vinay Sharma](https://wiki.jderobot.org/Club-VinaySharma) (GSoC-2018) DeepLearning, DetectionSuite tool
- [Nigel Fernandez](https://wiki.jderobot.org/Ni9elf-colab) GSoC-2017
- [Okan Asik](https://wiki.jderobot.org/Okanasik-colab) GSoC-2017, VisualStates tool
- [S.Mehdi Mohaimanian](https://wiki.jderobot.org/index.php?title=Deep_Reinforcement_Learning_in_Robotic&redirect=no) GSoC-2017
- [Raúl Pérula](https://wiki.jderobot.org/Raulperula-colab) GSoC-2017, Scratch2JdeRobot tool
- [Lihang Li](https://wiki.jderobot.org/Hustcalm-colab): GSoC-2015, Visual SLAM, RGBD, 3D Reconstruction
- [Andrei Militaru](https://wiki.jderobot.org/Militaru92-colab) GSoC-2015, interoperation of ROS and JdeRobot
- [Satyaki Chakraborty](https://wiki.jderobot.org/Chakraborty-colab) GSoC-2015, Interconnection with Android Wear


# How to increase your chances of being selected in GSoC-2022

If you put yourself in the shoes of the mentor that should select the student, you'll immediately realize that there are some behaviors that are usually rewarded. Here's some examples.

1. **Be proactive**: Mentors are more likely to select students that openly discuss the existing ideas and / or propose their own. It is a **bad idea** to just submit your idea only in the Google web site without discussing it, because it won't be noticed.

2. **Demonstrate your skills**: Consider that mentors are being contacted by several students that apply for the same project. A way to show that you are the best candidate, is to demonstrate that you are familiar with the software and you can code. How? Browse the bug tracker (issues in github of JdeRobot project), fix some bugs and propose your patch submitting your PullRequest, and/or ask mentors to challenge you! Moreover, bug fixes are a great way to get familiar with the code.

3. **Demonstrate your intention to stay**: Students that are likely to disappear after GSoC are less likely to be selected. This is because there is no point in developing something that won't be maintained. And moreover, one scope of GSoC is to bring new developers to the community.

# [RTFM](https://xkcd.com/293/)

Read the relevant information about GSoC in the wiki / web pages before asking. Most FAQs have been answered already!

- [Full documentation about GSoC on official website](https://developers.google.com/open-source/gsoc/resources/).
- [FAQ from GSoC web site](https://developers.google.com/open-source/gsoc/faq).
- If you are new to JdeRobot, take the time to familiarize with the [JdeRobot](https://jderobot.org).
