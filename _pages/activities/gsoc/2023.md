---
permalink: /activities/gsoc/2023
title: "GSoC 2023 (in case of being selected)"

youtubeId1: wmAeoyiUyh4
youtubeId2: 07RnI9bXysk
youtubeId3: Y5VvQAP6cMI
youtubeId4: AGJlCJ6UXPs
youtubeId5: gDP9nWCL0Vg
youtubeId6: kJMPz80w9BM
youtubeId7: YMMQVo_3oh8
youtubeId8: ufvPS5wJAx0
youtubeId9: y7rBPpV2NdI
youtubeId10: BpHSDrFqpVk
youtubeId11: yKXP3UIAxtg
youtubeId12: tzxxEyA-LWs
youtubeId13: s-S5mQp9i1Y
youtubeId14: 4yKM3EuEv_g
youtubeId15: NrzmH_yerBU
youtubeId16: 97JRYhKLhSY
youtubeId17: vn4ahq8mElg
youtubeId18: sXqZvsV5lzc
youtubeId19: RfW2hI_8j74
youtubeId20: Xs3iAPYRtVQ
youtubeId21: J6bDlE7TofE
youtubeId41: W3XirsadmNg
youtubeId50: 7s4vpMGU2Mg

sidebar:
  nav: "docs"

toc: true
toc_label: "TOC GSoC-2023 (in case of being selected)"
toc_icon: "cog"

projects:

---

Robotics applications are typically distributed, made up of a collection of concurrent asynchronous components which communicate using some middleware (ROS messages, DDS...). Building robotics applications is a complex task. Integrating existing nodes or libraries that provide already solved functionality, and using several tools may increase the software robustness and shorten the development time. JdeRobot provides several tools, libraries and reusable nodes. They have been written in C++, Python or JavaScript. They are ROS-friendly and full compatible with ROS-Noetic (and Gazebo11).


Our community mainly works on four development areas:
- Education in Robotics. [RoboticsAcademy](https://jderobot.github.io/RoboticsAcademy/) is our main project. It is a ROS-based framework to learn robotics and computer vision with drones, autonomous cars.... It is a collection of Python programmed exercises for engineering students. 

- Robot Programming Tools. For instance, [VisualCircuit](https://jderobot.github.io/VisualCircuit/) for robot programming with connected blocks, as in eleectronic circuits, in a visual way.

- MachineLearning in Robotics. For instance, [DeepLearningStudio](https://github.com/JdeRobot/DeepLearningStudio) to explore the use neural networks for robot control. It includes the [BehaviorMetrics tool](https://jderobot.github.io/BehaviorMetrics/) for assessment of neural networks for autonomous driving. [RL-Studio](https://github.com/JdeRobot/RL-Studio), a library for the training of Reinforcement Learning algorithms for robot control. [DetectionMetrics tool](https://github.com/JdeRobot/DetectionMetrics) for evaluation of visual detection neural networks and algorithms.

- Reconfigurable Computing in Robotics. [FPGA-Robotics](https://github.com/JdeRobot/FPGA-robotics) for programming robots with reconfigurable computing (FPGAs) using open tools as IceStudio and Symbiflow. Verilog-based reusable blocks for robotics applications.







# Ideas list

This open source organization welcomes contributors in these topics:


## Project #1: RoboticsAcademy: Cross-Platform Desktop Application using ElectronJS

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS or openCV. 

Currently, the platform offers its resources through a website, making it difficult for users to access and manage the content.The objective of this project is to develop a cross-platform desktop application for the Robotics Academy using ElectronJS. The application will provide a convenient and user-friendly interface for users to access and manage the content, making it more accessible and efficient for users to learn and explore the world of robotics.

The scope of this project is to develop a cross-platform desktop application for the Robotics Academy using ElectronJS. The application will be designed to provide a user-friendly interface for users to access and manage the resources and content available on the Robotics Academy platform. The project will involve the integration of the existing resources and content into the application, as well as the implementation of features such as resource management and a user-friendly interface. The project will also include thorough testing and bug fixing to ensure the stability and usability of the application. Finally, the project will involve documenting the project and providing clear instructions for future maintenance and development.

{% include youtubePlayer.html id=page.youtubeId7 %}

- **Skills required/preferred:** Proficiency in JavaScript and ElectronJS framework
- **Difficulty rating:** medium
- **Expected results:** desktop application for Robotics Academy
- **Expected size:** 175h
- **Mentors:** Apoorv Garg (apoorvgarg.ms AT gmail.com) 



## Project #2: Robotics Academy: migration to ROS2 Humble

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS or OpenCV.

Nowadays, Robotics Academy offers the student up to 26 exercises, and another 11 prototype exercises. All of them come ready to use in the RoboticsAcademy docker image (RADI). The only requirement for the students its to download the docker image, all the dependencies are installed inside the RADI.

The RADI is one key point of the platform and Project #2 aims to keep improving it. One main component of the RADI is [ROS](https://www.ros.org/). Currently, the RADI is based in ROS noetic version, which its end of life ([in May, 2025](http://wiki.ros.org/Distributions)) is getting closer. **The main goal of the project is to migrate the RADI to ROS2**. Moving from a ros *one* distritution to a ros *two* distribution is a major improvement. This migration will take form by having a couple of exercises running in ROS2 with the new RADI.

Back in time, some ROS2 Foxy exercise prototypes were implemented. For more information, have a look at [GSoC 2021 project](https://theroboticsclub.github.io/gsoc2021-Siddharth_Saha/milestones/2021/08/21/final-report) and corresponding academy exercises [1](https://jderobot.github.io/RoboticsAcademy/exercises/MobileRobots/single_robot_amazon_warehouse/) and [2](https://jderobot.github.io/RoboticsAcademy/exercises/MobileRobots/multi_robot_amazon_warehouse/).

Besides, Project #2 may **also explore** some RADI related topics as **size optimization**, **multi-rosdistro docker image** or **hardware acceleration**.

The project is bound to Project #3, and both students will work together in the new RADI.

<figure class="half">
    <a href=""><iframe src="https://www.youtube.com/embed/wmAeoyiUyh4"></iframe></a>
    <a href=""><iframe src="https://www.youtube.com/embed/RfW2hI_8j74"></iframe></a>
 </figure>

- **Skills required/preferred:** Docker, ROS2, Python and ROS.
- **Difficulty rating:** medium
- **Expected results:** New docker image based on ROS2.
- **Expected size:** 175h
- **Mentors:** Pedro Arias (pedro.ariasp AT upm.com)


## Project #3: Robotics Academy: migration to Gazebo Fortress

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS or openCV.

Nowadays, Robotics Academy offers the student up to 26 exercises, and another 11 prototype exercises. All of them come ready to use in the RoboticsAcademy docker image (RADI). The only requirement for the students its to download the docker image, all the dependencies are installed inside the RADI.

The RADI is one key point of the platform and Project #3 aims to keep improving it. One main component of the RADI is [Gazebo](https://gazebosim.org/home). Currently, the RADI is based in Gazebo11 version, which its end of life ([in Sep, 2025](https://classic.gazebosim.org/#status)) is getting closer. **The main goal of the project is to migrate the RADI to Gazebo Fortress**. This migration will take form by having a couple of exercises running in ROS2 with the new RADI.

The project is bound to Project #2, and both students will work together in the new RADI.

- **Skills required/preferred:** Docker, Gazebo Ignition Fortress, Python and ROS/ROS2.
- **Difficulty rating:** medium
- **Expected results:** New docker image based on Gazebo Fortress. 
- **Expected size:** 175h
- **Mentors:** Pedro Arias (pedro.ariasp AT upm.com)


## Project #4: Robotics-Academy: improve Deep Learning based Human Detection exercise

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS or openCV.

The idea for this project is to improve the ["Human detection" Deep Learning exercise](https://jderobot.github.io/RoboticsAcademy/exercises/ComputerVision/human_detection) at Robotics-Academy, developed along GSoC-2021. Instead of asking the user to code the solution in a web-based editor, he or she will have to upload a deep learning model that matches video inputs and outputs the image coordinates of the detected humans. In this project, the support for neural network models in the open [ONNX format](https://onnx.ai/), which is becoming a standard, is one goal. The exercise fluent execution is also a goal, hopefully taking advantage of GPU at the user's machine from the RoboticsAcademy docker container. An automatic evaluator to test the performance of the network provided by the user will be also explored. All the above functionalities have, to some extent, already been implemented in the exercise. The goal is to improve/refine them either on the existing implementation or from scratch.
In short, the scope of improvements in the exercise include:

- Custom train or find an enhanced DL model trained to detect only humans specifically. Changes to the pre-processing and post-processing part would have to be made as per the input and output structure of the new model.
- Enhancing the model benchmarking part in terms of its interpretability, use case, accuracy, and visual appeal to the user. 
- Enabling GPU support while executing the exercise from the docker container.
- Fluent exercise execution.
- Other scopes of improvements are also welcome. This may include adding/modifying features and making the exercise more user-friendly and easy to use.

{% include youtubePlayer.html id=page.youtubeId17 %}

- **Skills required/preferred:** Python, OpenCV, PyTorch/Tensorflow
- **Difficulty rating:** medium
- **Expected results:** a web-based exercise for solving a visual detection task using deep learning
- **Expected size:** 175h
- **Mentors:** David Pascual (d.pascualhe AT gmail.com) and Shashwat Dalakoti (shash.dal623 AT gmail.com)



## Project #5: Robotics-Academy: new exercise using Deep Learning for Visual Control

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS or openCV.

The idea for this project is to develop a new deep learning exercise for visual robotic control within the Robotics-Academy context. We will build a web-based interface that allows the user to input a trained model that matches as input the camera installed on a drone or a car, and as outputs the linear speed and angular velocity of the vehicle. The controlled robot and its environment will be simulated using Gazebo. In this project, we will:
- Update the web interface for accepting models trained with PyTorch/Tensorflow as input.
- Build new widgets for monitoring results for the particular exercise.
- Get a simulated environment ready.
- Code the core application that will feed the trained model with input data and send back the results.
- Train a naive model that allow us to show how the exercise can be solved.

This new exercise may reuse the infrastructure developed for the ["Human detection" Deep Learning exercise](https://jderobot.github.io/RoboticsAcademy/exercises/ComputerVision/human_detection). The following videos show one of our current web-based exercises and a visual control task solved using deep learning:

{% include youtubePlayer.html id=page.youtubeId14 %}

{% include youtubePlayer.html id=page.youtubeId50 %}

- **Skills required/preferred:** Python, OpenCV, PyTorch/Tensorflow, Gazebo
- **Difficulty rating:** medium
- **Expected results:** a web-based exercise for robotic visual control using deep learning
- **Expected size:** 175h
- **Mentors:** David Pascual ( d.pascualhe AT gmail.com ) and Pankhuri Vanjani (pankhurivanjani AT gmail.com)



## Project #6: Robotics-Academy: support for raw robotics applications, without template

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. The students have to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries such as ROS or openCV.

For each exercise there is a webpage (exercise.html) and a Python template (exercise.py), both connected through websockets. The webpages are the Graphical User Interface (GUI) of each RoboticsAcademy exercise and they use several web templates. The browser connects with the Docker image application in order to run the simulation and to allow the users to send their code and see the results of the simulation. Nowadays, the web-templates have been developed using plain HTML, Javascript and CSS and we aim to improve them by using advanced frontend technologies such as React, Vue, Angular or Flutter. 

[![Color filter](https://img.youtube.com/vi/Fv9s99IEIvc/0.jpg)](https://www.youtube.com/watch?v=Fv9s99IEIvc)

{% include youtubePlayer.html id=page.youtubeId18 %} 

- **Skills required/preferred:** Python, JavaScript, HTML, CSS
- **Difficulty rating:** medium
- **Expected results:** Upgrade the current web templates of all exercises to use a more advanced frontend technology.
- **Expected size:** 350h
- **Mentors:** David Roldán (david.roldan AT urjc.es) and Jose María Cañas (josemaria.plaza AT urjc.es)



## Project #7: Dockerization of Visual Circuit

**Brief Explanation**: VisualCircuit allows users to program robotic intelligence using a visual language which consists of blocks and wires, as electronic circuits. The last year focused on migrating the old POSIX IPC implementation to a Cross Platform compatible Python Shared Memory Implementation. In addition, new functions for sharing data as well as applications demos and functionality to support Finite State Machines were added. A web service of Visual Circuit also exists. Currently, the process to build a Visual Circuit application is simple: Edit Application on the Web → Download Python Application File → Run Locally. You can read further about the tool on the [website](https://jderobot.github.io/VisualCircuit/).

The aim for this year is to make Visual Circuit easy to host and deploy for a larger audience. To that end, we want to build a Docker image of the application. The final goal of this Docker implementation is to smoothly bundle Visual Circuit along with Robotics Academy. Aside from this, we want to make the process of adding blocks to Visual Circuit easier by creating a GitHub Repo where people can contribute their designs, these designs will then be verified by maintainers and then merged. Any new Robotics Academy applications made using Visual Circuit will be a good bonus.

 <img src="/assets/images/activities/gsoc/VisualCircuit3.png" width="80%" height="80%">

{% include youtubePlayer.html id=page.youtubeId20 %}

- **Skills required/preferred:** Python, Docker, ROS, React and some basic JavaScript knowledge
- **Difficulty rating:** medium
- **Expected results:** A dockerized version of Visual Circuit, a new repository and workflow for adding blocks to Visual Circuit, good documentation for both of the above.
- **Expected size:** 175h
- **Mentors:** Toshan Luktuke (toshan1603 AT gmail.com)



## Project #8: optimization of Deep Learning models for autonomous driving

**Brief explanation**: [BehaviorMetrics](https://jderobot.github.io/BehaviorMetrics) is a tool used to compare different autonomous driving architectures. It uses [Gazebo](http://gazebosim.org/), a well-known really powerful robotics simulator and [ROS Noetic](http://wiki.ros.org/noetic). We are currently able to drive a car autonomously on different circuits using deep learning models to do the robot control processing. Check out the videos below to get an insight. 

For this project, we would like to improve the current model stack based on deep learning, applying some optimization techniques to make them run faster without losing precision. Since the hardware devices used to do the inference in real world scenarios usually have a small amount of compute capabilities, we would like to apply speed up techniques on our models or explore new model architectures with low inference time. Some references:

* [TensorRT](https://developer.nvidia.com/tensorrt)
* [Quantization](https://www.tensorflow.org/api_docs/python/tf/quantization/quantize)

 <img src="/assets/images/activities/gsoc/behavior-metrics-screenshot.png" width="80%" height="80%">
{% include youtubePlayer.html id=page.youtubeId21 %}

<!--
<figure class="half">
    <img src="/assets/images/activities/gsoc/behavior-metrics-screenshot.png">
    <a href=""><iframe src="https://www.youtube.com/embed/J6bDlE7TofE"></iframe></a>
 </figure>
-->

- **Skills required/preferred:** Python and deep learning knowledge (Tensorflow/PyTorch).
- **Difficulty rating:** medium
- **Expected results:** new autonomous driving deep learning models optimized for lower inference time.
- **Expected size:** 175h
- **Mentors:** Sergio Paniego Blanco (sergiopaniegoblanco AT gmail.com) and Utkarsh Mishra ( utkarsh75477 AT gmail.com )


## Project #9: DeepLearning models for autonomous drone piloting and support in BehaviorMetrics

**Brief Explanation**: [BehaviorMetrics](https://jderobot.github.io/BehaviorMetrics) is a tool used to compare different autonomous driving architectures. It uses [Gazebo](http://gazebosim.org/), a well-known really powerful robotics simulator and [ROS Noetic](http://wiki.ros.org/noetic). During a past GSoC 2021 [project](https://theroboticsclub.github.io/gsoc2021-Utkarsh_Mishra/gsoc/Summary-and-Recap/), we explored the addition of drone support for Behavior Metrics. We were able to add this support for IRIS drone, so we would like to exploring adding autonomous drone piloting techniques based on deep learning for this configuration. 

We would like to generate new drone scenarios specially suited for the robot control problem, train deep learning models based on state of the art architectures and refine this support in the BehaviorMetrics stack. The drone 3D control is a step forward from the 2D car control, as there is an additional degree of freedom and the onboard camera orientation typically significantly oscillates while the vehicle is moving in 3D.

<figure class="half">
    <a href=""><iframe src="https://www.youtube.com/embed/GZs6OIQ_az0"></iframe></a>
    <a href=""><iframe src="https://www.youtube.com/embed/pbYfdXvtRLo"></iframe></a>
 </figure>

- **Skills required/preferred:** Python and deep learning knowledge (specially PyTorch).
- **Difficulty rating:** hard
- **Expected results:** broader support for the autonomous driving drone using Gazebo and PyTorch.
- **Expected size:** 350 hours
- **Mentors:** Sergio Paniego Blanco (sergiopaniegoblanco AT gmail.com) and Nikhil Paliwal ( nikhil.paliwal14 AT gmail.com )



## Project #10: Robotics Academy: migration of several exercises from ROS1 to ROS2 Humble and refinement

**Brief Explanation**: Currently most RoboticsAcademy exercises are based on ROS1 Noetic and Gazebo 11. There are also several prototypes of ROS2 Foxy based exercises which require refinement. The main goal of this project is to migrate several RADI-3 exercises to RADI-4, updating the models of the robots involved in those exercises to their homologous model in ROS2. This will require understanding the complete infrastructure and modifying exercises to use ROS2 communications. In addition, the support for several ROS tools (such as rqt_graph and Rviz) from the corresponding exercise webpages should be implemented (using VNC mainly). New exercises integrating the ROS2 Navigation stack are also welcome, which involve the use of functionalities such as collision avoidance, global path planning, and Multi-robot coordination.

ROS2 has put forward several improvements over ROS with changes in middleware and software architecture in many aspects. In this project, we would focus on developing new exercises with ROS2. For more information on ROS2 based exercises, have a look at [GSoC 2021 project](https://theroboticsclub.github.io/gsoc2021-Siddharth_Saha/milestones/2021/08/21/final-report) and corresponding academy exercises [1](https://jderobot.github.io/RoboticsAcademy/exercises/MobileRobots/single_robot_amazon_warehouse/) and [2](https://jderobot.github.io/RoboticsAcademy/exercises/MobileRobots/multi_robot_amazon_warehouse/). In addition to porting exercises, contributors are also welcome to suggest improvements to the current RADI framework.

{% include youtubePlayer.html id=page.youtubeId19 %}
{% include youtubePlayer.html id=page.youtubeId1 %}

- **Skills required/preferred:** C++, Python programming skills, experience with ROS. Good to know: ROS2
- **Difficulty rating:** hard
- **Expected results:** Migrating the current web template exercises from (ROS1 based) RADI-3 to (ROS2 based) RADI-4
- **Expected size:** 350 hours
- **Mentors:** Siddharth Saha (sahasiddharth611 AT gmail.com) and Shreyas Gokhale (shreyas6gokhale AT gmail.com).

# Application instructions for GSoC-2023

We welcome students to contact relevant mentors before submitting their application into GSoC official website. If in doubt for which project(s) to contact, send a message to jderobot AT gmail.com We recommend browsing previous GSoC student pages to look for ready-to-use projects, and to get an idea of the expected amount of work for a valid GSoC proposal.

## Requirements

* Git experience
* C++ and Python programming experience (depending on the project)

## Programming tests

|    **Project**   |     [#1](https://jderobot.github.io/activities/gsoc/2022#project-1-robotics-academy-optimization-of-exercise-templates)     |      [#2](https://jderobot.github.io/activities/gsoc/2022#project-2-robotics-academy-consolidation-of-drone-based-exercises)      |     [#3](https://jderobot.github.io/activities/gsoc/2022#project-3-robotics-academy-improvement-of-autonomous-driving-exercises)     |     [#4](https://jderobot.github.io/activities/gsoc/2022#project-4-robotics-academy-improve-deep-learning-based-human-detection-exercise)     |     [#5](https://jderobot.github.io/activities/gsoc/2022#project-5-robotics-academy-new-exercise-using-deep-learning-for-visual-control)     |     [#6](https://jderobot.github.io/activities/gsoc/2022#project-6-robotics-academy-improvement-of-the-web-templates-using-powerful-frontend-technologies)     |     [#7](https://jderobot.github.io/activities/gsoc/2022#project-7-improvement-of-visualcircuit-web-service)     |     [#8](https://jderobot.github.io/activities/gsoc/2022#project-8-optimization-of-deep-learning-models-for-autonomous-driving)     |     [#9](https://jderobot.github.io/activities/gsoc/2022#project-9-deeplearning-models-for-autonomous-drone-piloting-and-support-in-behaviormetrics)     |     [#10](https://jderobot.github.io/activities/gsoc/2022#project-10-robotics-academy-migration-of-several-exercises-from-ros1-to-ros2-and-refinement)    |
| **Academy (A)** |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |
|    **C++ (B)**   |     O     |     O     |     O     |     O     |     O     |     O     |     O     |     O     |     O     |     X     |
|  **Python (C)**  |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |
|  **ROS2 (D)**  |     O     |     O     |     O     |     O     |     O     |     -     |     -     |     -     |     -     |     X     |

<br/>

|               Where:                     ||
| * |             Not applicable            |
| X |                Mandatory              |
| O |                Optative               |


Before accepting any proposal all candidates have to do these programming challenges:

- (A) [RoboticsAcademy challenge](https://drive.google.com/file/d/1UaZt43_Sl-vI-mD_D6bRNWXLQpywdrIF/view?usp=sharing)
- (B) [C++ challenge](https://drive.google.com/file/d/1GO0GJIi7rNqZXhPEaV8Qf0Ds4qFHczJ2/view?usp=sharing)
- (C) [Python challenge](https://drive.google.com/file/d/1Mzr-jGvwCpuZoFKmvjXzJxTfjbf2K16w/view?usp=sharing)
- (D) [ROS2 challenge](https://drive.google.com/file/d/1q3-43jxPPqQRjRB_tX7Y_N07YKOfToC3/view?usp=sharing)

## Send us your information

AFTER doing the programming tests, fill this [web form](https://docs.google.com/forms/d/e/1FAIpQLSfQAt6NbTP_Thag4fa638zmXqR1gnPGQOYDOupIQ6ram9d1BA/viewform) with your information and challenge results. Then you are invited to ask the project mentors about the project details. Maybe we will require more information from you like this:


1. Contact details
   - Name and surname:
   - Country:
   - Email:
   - Public repository/ies:
   - Personal blog (optional):
   - Twitter/Identica/LinkedIn/others:
2. Timeline
   - Now split your project idea in smaller tasks. Quantify the time you think each task needs. Finally, draw a tentative project plan (timeline) including the dates covering all period of GSoC. Don’t forget to include also the days in which you don’t plan to code, because of exams, holidays etc.
   - Do you understand this is a serious commitment, equivalent to a full-time paid summer internship or summer job?
   - Do you have any known time conflicts during the official coding period?
3. Studies
   - What is your School and degree?
   - Would your application contribute to your ongoing studies/degree? If so, how?
4. Programming background
   - Computing experience: operating systems you use on a daily basis, known programming languages, hardware, etc.
   - Robot or Computer Vision programming experience:
   - Other software programming:
5. GSoC participation
   - Have you participated to GSoC before?
   - How many times, which year, which project?
   - Have you applied but were not selected? When?
   - Have you submitted/will you submit another proposal for GSoC 2023 to a different org?



# Previous GSoC students

- [Apoorv Garg](https://theroboticsclub.github.io/gsoc2022-Apoorv_Garg/) (GSoC-2022) Improvement of Web Templates of Robotics Academy exercises
- [Toshan Luktuke](https://theroboticsclub.github.io/gsoc2022-Toshan_Luktuke/) (GSoC-2022) Improvement of VisualCircuit web service
- [Nikhil Paliwal](https://theroboticsclub.github.io/gsoc2022-Nikhil_Paliwal/)(GSoC-2022) Optimization of Deep Learning models for autonomous driving
- [Akshay Narisetti](https://theroboticsclub.github.io/gsoc2022-Akshay_Narisetti/)(GSoC-2022) Robotics Academy: improvement of autonomous driving exercises
- [Prakarsh Kaushik](https://theroboticsclub.github.io/gsoc2022-Prakarsh_Kaushik/)(GSoC-2022) Robotics Academy: consolidation of drone based exercises
- [Bhavesh Misra](https://theroboticsclub.github.io/gsoc2022-Bhavesh_Misra/) (GSoC-2022) Robotics Academy: improve Deep Learning based Human Detection exercise
- [Suhas Gopal](https://theroboticsclub.github.io/gsoc2021-Suhas_Gopal/) (GSoC-2021) Shifting VisualCircuit to a web server
- [Utkarsh Mishra](https://theroboticsclub.github.io/gsoc2021-Utkarsh_Mishra/) (GSoC-2021) Autonomous Driving drone with Gazebo using Deep Learning techniques
- [Siddharth Saha](https://theroboticsclub.github.io/gsoc2021-Siddharth_Saha/) (GSoC-2021) Robotics Academy: multirobot version of the Amazon warehouse exercise in ROS2
- [Shashwat Dalakoti](https://theroboticsclub.github.io/gsoc2021-Shashwat_Dalakoti/) (GSoC-2021) Robotics-Academy: exercise using Deep Learning for Visual Detection
- [Arkajyoti Basak](https://theroboticsclub.github.io/gsoc2021-Arkajyoti_Basak/) (GSoC-2021) Robotics Academy: new drone based exercises
- [Chandan Kumar](https://theroboticsclub.github.io/gsoc2021-Chandan_Kumar/) (GSoC-2021) Robotics Academy: Migrating industrial robot manipulation
 exercises to web server
- [Muhammad Taha](https://theroboticsclub.github.io/colab-gsoc2020-Muhammad_Taha/) (GSoC-2020) VisualCircuit tool, digital electronics language for robot behaviors.
- [Sakshay Mahna](https://theroboticsclub.github.io/colab-gsoc2020-Sakshay_Mahna/) (GSoC-2020) Robotics-Academy exercises on Evolutionary Robotics.
- [Shreyas Gokhale](https://theroboticsclub.github.io/colab-gsoc2020-Shreyas_Gokhale/) (GSoC-2020) Multi-Robot exercises for Robotics Academy In ROS2.
- [Yijia Wu](https://theroboticsclub.github.io/colab-gsoc2020-Yijia_Wu/) (GSoC-2020) Vision-based Industrial Robot Manipulation with MoveIt.
- [Diego Charrez](https://theroboticsclub.github.io/colab-gsoc2020-Diego_Charrez/logbook/) (GSoC-2020) Reinforcement Learning for Autonomous Driving with Gazebo and OpenAI gym.
- [Nikhil Khedekar](https://theroboticsclub.github.io/colab-gsoc2019-Nikhil_Khedekar/) (GSoC-2019) Migration to ROS of drones exercises on JdeRobot Academy
- [Shyngyskhan Abilkassov](https://theroboticsclub.github.io/colab-gsoc2019-Shyngyskhan_Abilkassov) (GSoC-2019) Amazon warehouse exercise on JdeRobot Academy
- [Jeevan Kumar](https://theroboticsclub.github.io/colab-gsoc2019-Jeevan_Kumar/) (GSoC-2019) Improving DetectionSuite DeepLearning tool
- [Baidyanath Kundu](https://theroboticsclub.github.io/colab-gsoc2019-Baidyanath_Kundu/) (GSoC-2019) A parameterized automata Library for VisualStates tool
- [Srinivasan Vijayraghavan](https://theroboticsclub.github.io/colab-gsoc2019-Srinivasan_Vijayraghavan/) (GSoC-2019) Running Python code on the web browser
- [Pankhuri Vanjani](https://theroboticsclub.github.io/colab-gsoc2019-Pankhuri_Vanjani/) (GSoC-2019) Migration of JdeRobot tools to ROS 2
- [Pushkal Katara](https://wiki.jderobot.org/Club-PushkalKatara) (GSoC-2018) VisualStates tool
- [Arsalan Akhter](https://wiki.jderobot.org/Club-aakhter) (GSoC-2018) Robotics-Academy
- [Hanqing Xie](https://wiki.jderobot.org/Club-hanqingxie) (GSoC-2018) Robotics-Academy
- [Sergio Paniego](https://wiki.jderobot.org/Club-spaniego) (GSoC-2018) PyOnArduino tool
- [Jianxiong Cai](https://wiki.jderobot.org/Club-jianxiong) (GSoC-2018) Creating realistic 3D map from online SLAM result
- [Vinay Sharma](https://wiki.jderobot.org/Club-VinaySharma) (GSoC-2018) DeepLearning, DetectionSuite tool
- [Nigel Fernandez](https://wiki.jderobot.org/Ni9elf-colab) GSoC-2017
- [Okan Asik](https://wiki.jderobot.org/Okanasik-colab) GSoC-2017, VisualStates tool
- [S.Mehdi Mohaimanian](https://wiki.jderobot.org/index.php?title=Deep_Reinforcement_Learning_in_Robotic&redirect=no) GSoC-2017
- [Raúl Pérula](https://wiki.jderobot.org/Raulperula-colab) GSoC-2017, Scratch2JdeRobot tool
- [Lihang Li](https://wiki.jderobot.org/Hustcalm-colab): GSoC-2015, Visual SLAM, RGBD, 3D Reconstruction
- [Andrei Militaru](https://wiki.jderobot.org/Militaru92-colab) GSoC-2015, interoperation of ROS and JdeRobot
- [Satyaki Chakraborty](https://wiki.jderobot.org/Chakraborty-colab) GSoC-2015, Interconnection with Android Wear


# How to increase your chances of being selected in GSoC-2022

If you put yourself in the shoes of the mentor that should select the student, you'll immediately realize that there are some behaviors that are usually rewarded. Here's some examples.

1. **Be proactive**: Mentors are more likely to select students that openly discuss the existing ideas and / or propose their own. It is a **bad idea** to just submit your idea only in the Google web site without discussing it, because it won't be noticed.

2. **Demonstrate your skills**: Consider that mentors are being contacted by several students that apply for the same project. A way to show that you are the best candidate, is to demonstrate that you are familiar with the software and you can code. How? Browse the bug tracker (issues in github of JdeRobot project), fix some bugs and propose your patch submitting your PullRequest, and/or ask mentors to challenge you! Moreover, bug fixes are a great way to get familiar with the code.

3. **Demonstrate your intention to stay**: Students that are likely to disappear after GSoC are less likely to be selected. This is because there is no point in developing something that won't be maintained. And moreover, one scope of GSoC is to bring new developers to the community.

# [RTFM](https://xkcd.com/293/)

Read the relevant information about GSoC in the wiki / web pages before asking. Most FAQs have been answered already!

- [Full documentation about GSoC on official website](https://developers.google.com/open-source/gsoc/resources/).
- [FAQ from GSoC web site](https://developers.google.com/open-source/gsoc/faq).
- If you are new to JdeRobot, take the time to familiarize with the [JdeRobot](https://jderobot.org).
